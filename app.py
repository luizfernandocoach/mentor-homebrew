import streamlit as st
import google.generativeai as genai
import time
import os

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Mentor Homebrew", page_icon="üß†", layout="wide")

# --- GEST√ÉO DE ACESSO (SEUS 5 PRIMEIROS CLIENTES) ---
# Dica: Mude as senhas antes de enviar!
USUARIOS = {
    "admin": "homebrew2025",    # Voc√™
    "cliente1": "treino01",     # Personal 1
    "cliente2": "forca02",      # Personal 2
    "cliente3": "saude03",      # Personal 3
    "cliente4": "meta2025",     # Personal 4
    "cliente5": "vip05"         # Personal 5
}

# --- FUN√á√ÉO DE LOGIN ---
def check_password():
    if st.session_state.get("logged_in"): return True
    
    # Design da Tela de Login
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("## üîê Mentor AI: Acesso Exclusivo")
        st.info("Entre com suas credenciais de assinante.")
        u = st.text_input("Usu√°rio")
        p = st.text_input("Senha", type="password")
        if st.button("Acessar Sistema"):
            if u in USUARIOS and USUARIOS[u] == p:
                st.session_state["logged_in"] = True
                st.rerun()
            else: st.error("Acesso negado.")
    return False

# --- CONFIGURA√á√ÉO DA API (AUTOM√ÅTICA) ---
def configure_api():
    # Tenta pegar do cofre (Secrets)
    api_key = st.secrets.get("GOOGLE_API_KEY")
    
    if not api_key:
        st.error("ERRO CR√çTICO: Chave de API n√£o configurada no servidor.")
        st.stop()
        
    return api_key

# --- FUN√á√ÉO INTELIGENTE DE MODELO ---
def get_best_model():
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if 'flash' in m.name: return m.name
        return 'models/gemini-pro'
    except: return 'models/gemini-1.5-flash'

# --- CARREGAMENTO DA BIBLIOTECA ---
@st.cache_resource
def load_library_robust(api_key):
    # Caminho absoluto para evitar erro de pasta
    current_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_dir, "files", "biblioteca_mestre.pdf")
    
    if not os.path.exists(file_path):
        return None, f"Erro interno: Arquivo de base n√£o encontrado."
        
    try:
        genai.configure(api_key=api_key)
        # Verifica se j√° existe um arquivo com esse nome no Google para n√£o subir duplicado (Otimiza√ß√£o)
        # Para o MVP simples, vamos subir sempre para garantir que funcione
        file_ref = genai.upload_file(file_path, mime_type="application/pdf")
        
        # Espera ficar ATIVO
        for _ in range(10):
            if file_ref.state.name == "ACTIVE": break
            if file_ref.state.name == "FAILED": return None, "Falha no processamento do arquivo."
            time.sleep(1)
            file_ref = genai.get_file(file_ref.name)
            
        return file_ref, None
    except Exception as e: return None, str(e)

# --- APP PRINCIPAL ---
if check_password():
    # BARRA LATERAL LIMPA (Sem campo de senha)
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2586/2586866.png", width=50)
        st.title("√Årea do Membro")
        st.success("Status: ‚úÖ Ativo")
        
        st.divider()
        if st.button("Sair / Logout"): 
            st.session_state["logged_in"] = False
            st.rerun()
        
        st.caption("v1.0 - Homebrew Tech")

    # √ÅREA PRINCIPAL
    st.title("Mentor AI: Especialista em Treinamento üèãÔ∏è")
    st.markdown("Use este chat para tirar d√∫vidas sobre fisiologia, biomec√¢nica e montagem de treino.")

    # 1. Configura API Silenciosamente
    api_key = configure_api()

    # 2. Conecta o C√©rebro
    if "library_ref" not in st.session_state or not st.session_state["library_ref"]:
        with st.spinner("Inicializando assistente inteligente..."):
            ref, err = load_library_robust(api_key)
            if err: st.error(f"Erro de conex√£o: {err}")
            else: st.session_state["library_ref"] = ref

    # 3. Chat
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Ol√°! Sou seu Mentor T√©cnico. Como posso ajudar com seus alunos hoje?"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input("Ex: Meu aluno sente dor no ombro durante o supino..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            container = st.empty()
            lib = st.session_state.get("library_ref")
            
            if lib:
                try:
                    model_name = get_best_model()
                    model = genai.GenerativeModel(model_name, 
                        system_instruction="Voc√™ √© um Mentor T√©cnico S√™nior. Responda APENAS com base no arquivo fornecido. Se a resposta n√£o estiver no livro, diga que n√£o consta na bibliografia.")
                    
                    # Gera resposta
                    response = model.generate_content([lib, prompt])
                    container.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    container.error(f"Erro moment√¢neo: {e}. Tente novamente.")
            else:
                container.error("O sistema est√° reconectando. Aguarde um instante e tente novamente.")
